setwd('/home/pierre/Téléchargements/plsda/R')
source('./plsda_dummies.R')
source('./plsda_fit.R')
source('./plsda_predict.R')
source('./plsda_pls.R')
source('./plsda_scale.R')
library(doParallel)

df <-as.data.frame(matrix(runif(1, 0, 2),nrow=1000, ncol=150))
plsda.cv(V1~., df)



plsda.cv<-function(formula,data,nfold=10){
  
  #Vérification que l'entrée est bien une formule Y~X
  if(plyr::is.formula(formula)==F){
    stop("formula must be R formula !")
  }
  
  #Récupération des X et Y
  X <- model.matrix(formula, data = data)
  X <- X[,-1] #suppression de l'intercept
  Y <- model.response(model.frame(formula, data = data))
  
  ncomp <- qr(X)$rank
  PRESS <- NULL
  for(j in 1:ncomp){

    
    press <- NULL
    
    s<-sample(1:nrow(X),nrow(X))
    ns<-trunc(nrow(X)/nfold)
    newX <- X[s,]
    newY <- Y[s]
    
    for(i in 1:nfold){
      #index du ième échantillon
      idx<-c((1+(i-1)*ns):(ns*(i)))
      
      #on divise les données test et entraînement
      
      X.train <- newX[-idx,]
      X.test <- newX[idx,]
      Y.train <- newY[-idx]
      Y.test <- plsda.dummies(newY)
      Y.test <- Y.test[idx,]
      train <- data.frame("Y"=Y.train, X.train)
      
      #on exécute le modèle sur les données d'appprentissage
      fit<-plsda.fit(Y~., train, ncomp = j)
      #on fait la prédiction sur X.test
      pred <- plsda.predict(fit, X.test, type ="posterior")
      
      #on calcule le press pour le ième échantillon
      press[i] <- sum((Y.test-pred)^2)
      
    }
    PRESS[j] <-as.numeric(sum(press))
  }
  
  ncomp <- which.min(PRESS)
  min.PRESS <- PRESS[ncomp]
  object=list("ncomp" = ncomp,
              "PRESS" = PRESS,
              "min.PRESS" = min.PRESS)
  
  class(object)<-"CV"
  return(object)
  
}





plsda.cv.parra<-function(formula,data,nfold=10){
  no_cores <- detectCores() - 1  
  registerDoParallel(cores=no_cores)  
  cl <- makeCluster(no_cores, type="FORK")  
  
  #Vérification que l'entrée est bien une formule Y~X
  if(plyr::is.formula(formula)==F){
    stop("formula must be R formula !")
  }
  
  #Récupération des X et Y
  X <- model.matrix(formula, data = data)
  X <- X[,-1] #suppression de l'intercept
  Y <- model.response(model.frame(formula, data = data))
  
  ncomp <- qr(X)$rank
  PRESS <- NULL
  #for(j in 1:ncomp){
  foreach(j=1:ncomp) %dopar% {
    
    press <- NULL
    
    s<-sample(1:nrow(X),nrow(X))
    ns<-trunc(nrow(X)/nfold)
    newX <- X[s,]
    newY <- Y[s]
    
    #for(i in 1:nfold){
    foreach(i=1:nfold) %dopar% {
      #index du ième échantillon
      idx<-c((1+(i-1)*ns):(ns*(i)))
      
      #on divise les données test et entraînement
      
      X.train <- newX[-idx,]
      X.test <- newX[idx,]
      Y.train <- newY[-idx]
      Y.test <- plsda.dummies(newY)
      Y.test <- Y.test[idx,]
      train <- data.frame("Y"=Y.train, X.train)
      
      #on exécute le modèle sur les données d'appprentissage
      fit<-plsda.fit(Y~., train, ncomp = j)
      #on fait la prédiction sur X.test
      pred <- plsda.predict(fit, X.test, type ="posterior")
      
      #on calcule le press pour le ième échantillon
      press[i] <- sum((Y.test-pred)^2)
      
    }
    PRESS[j] <-as.numeric(sum(press))
  }
  stopCluster(cl)
  
  ncomp <- which.min(PRESS)
  min.PRESS <- PRESS[ncomp]
  object=list("ncomp" = ncomp,
              "PRESS" = PRESS,
              "min.PRESS" = min.PRESS)
  
  class(object)<-"CV"
  return(object)
  
}

liste <- ''
listeparra <- ''
for (i in 2:50){
  time <- system.time(plsda.cv(V1~.,df,nfold=i))

  liste <- append(liste, time[['elapsed']])

}

for (i in 2:50){
  timeparra <- system.time(plsda.cv.parra(V1~.,df,nfold=i))
  listeparra <- append(listeparra, timeparra[['elapsed']])
  
}

liste

plot(liste, type='l', col='red', ylab='Temps (millisecondes)', xlab='Nb de nfold', main = 'Efficacité de la parrallélisation selon le nfold')
lines(listeparra,type='l', col='blue')
legend('topleft',legend = c('Sans parrallélisation','Avec parrallélisation'), col=c('red','blue'), lty = 1, cex=0.8)

