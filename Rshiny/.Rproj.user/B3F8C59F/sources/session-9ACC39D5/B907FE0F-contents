#' NIPALS Algorithm for Partial Least Square Discriminant Analysis
#'
#' This function performs NIPALS algorithm for PLS-DA regression.
#'
#' @param
#' formula an object of class "formula" (or one that can be coerced to that class): a symbolic description of the model
#' to be fitted. See specification of the formula in the 'Details' section.
#' @param
#' data is the dataframe containing the the variables in the model.
#' @param
#' ncomp is the number of components for X.
#' @return
#' An object of class 'PLSDA' is a list containing at least the following components :
#' @return
#' \code{X} the original dataframe of the predictors
#' \cr
#' \code{Y} the original variable to predict
#' \cr
#' \code{Yloadings} the matrix of loadings for Y.
#' \cr
#' \code{Yscores} the matrix of components for Y.
#' \cr
#' \code{Xloadings} the matrix of loadings for X.
#' \cr
#' \code{Xloading.weights} the matrix of weights of the loadings of X.
#' \cr
#' \code{Xscores}the matrix of components of X.
#' \cr
#' \code{TrainPlsData}the PLS-DA training data set.
#' \cr
#' \code{R2} the coefficient of determination of the PLS-DA.
#'
#' @examples
#'pls.t1<-plsda.pls(Species~.,data = iris, ncomp = 2)
#'pls.t1<-plsda.pls(Species~.,data = iris, ncomp = 2, center = TRUE)

# ALGORITHME NIPPALS DE LA PLS
# X *= Variables explicatives
# Y *= Variable à expliquer (factor)
# ncomp *= Nombre de composante
plsda.pls <- function(formula, data, ncomp, center = F){

  #Vérification que l'entrée est bien une formule Y~X
  if(plyr::is.formula(formula)==F){
    stop("formula must be R formula !")
  }

  #Récupération des X et Y
  X <- model.matrix(formula, data = data)
  X <- X[,-1] #suppression de l'intercept
  Y <- model.response(model.frame(formula, data = data))

  # Cohérence de Y
  if(is.factor(Y)==F && is.vector(Y)==F){stop("Dimension de Y incorrecte") }

  if(!(is.factor(Y))){ Y <- as.factor(Y) }

  x <- as.matrix(X)
  #si le jeu de données entré n'est pas centré
  if(center == T){
    x <- plsda.scale(X)
    x <- as.matrix(x$New, ncol = 1)
  }
  y.dummies <- plsda.dummies(Y)

  #initialisation de la matrice des poids des composantes de X
  W <- data.frame(matrix(rep(0), nrow = ncol(x), ncol=ncomp))
  rownames(W) <- colnames(x)
  #initialisation de la matrice des composantes de X
  P <- data.frame(matrix(rep(0), nrow = ncol(x), ncol=ncomp))
  rownames(P) <- colnames(x)

  #initialisation de la matrice des scores de X
  Tx <- data.frame(matrix(rep(0), nrow = nrow(x), ncol=ncomp))

  #initialisation de la matrice des scores de Y
  U <- data.frame(matrix(rep(0), nrow = nrow(x), ncol=ncomp))

  #initialisation de la matrice des composantes de Y
  Q <- data.frame(matrix(rep(0), nrow = ncol(y.dummies), ncol = ncomp))
  rownames(Q) <- colnames(y.dummies)

  #on déroule l'algorithme NIPALS pour calculer les composantes de X et Y
  for(i in 1:ncomp){

    #on associe à u la première colonne de Yk-1
    u <- as.matrix(y.dummies[,1])
    j <- 1
    w <- W[,1]
    init <- (t(x)%*%u)/sum(u^2)

    #on normalise w
    init <- init/sqrt(sum(init^2))

    #on boucle jusqu'à ce que w converge
    while(abs(mean(w)-mean(init)) > 1e-10){

      #on n'associe pas init à w au premier tour
      if(j > 1){
        init <- w
      }

      #on calcule la composante t de la matrice Xk-1
      t <- x%*%init

      #calcul des poids de Yk-1
      q <- t(y.dummies)%*%t/sum(t^2)

      #calcul de la composante u de Xk-1
      u <- (y.dummies%*%q)/sum(q^2)

      #on met à jour le vecteur de poids
      w <- (t(x)%*%u)/sum(u^2)

      #on normalise w
      w <- w/sqrt(sum(w^2))

      j <- j+1
    }

    #SVD de Y
    U[,i] <- u

    #SVD de X
    Tx[,i] <- t

    #matrice des composantes de Y
    Q[,i] <- q

    #matrice des composantes "loadings" de la pls de R
    P[,i] <- t(x)%*%x%*%w
    c <- t(w)%*%t(x)%*%x%*%w
    P[,i] <- P[,i]/as.numeric(c)

    #mise à jour de la matrice des X
    x <- as.matrix(x - t%*%t(P[,i]))
    #mise à jour des Y
    y.dummies <- y.dummies - t%*%t(q)

    #on stocke le vecteur des poids de la composante i dans W[,i]
    W[,i] <- w

  }

  train_pls <- data.frame(Y, Tx)

  R2 <- cor(y.dummies, Tx)^2

  res <- list("X"=X,
              "Y"=Y,
              "Yloadings" = Q,
              "Yscores" = U,
              "Xloadings"= P,
              "Xloading.weights" = W,
              "Xscores" = Tx,
              "TrainPlsData" = train_pls,
              "R2" = R2
  )

  class(res)<-"PLS"
  return(res)

}
